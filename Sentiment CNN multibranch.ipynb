{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment CNN multibranch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiegoAnas/SNN-NLP/blob/master/Sentiment%20CNN%20multibranch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD2yitUiLcUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQwTZ12FxVIo",
        "colab_type": "code",
        "outputId": "792f31b8-bf5d-489d-dfe8-e055a9528a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, concatenate, Input, \\\n",
        " Embedding, Conv1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJdtm3MvxZ1C",
        "colab_type": "code",
        "outputId": "0575d49d-ec1c-47e4-c499-c8f9d7aea5a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# Parameters:\n",
        "# Word Embedding\n",
        "max_features = 10000\n",
        "maxlen = 400\n",
        "embedding_dims = 250\n",
        "\n",
        "# Convolution\n",
        "kernel_sizes = [3, 4, 5]  # or filter length\n",
        "filters = 250 \n",
        "pool_size = 4 \n",
        "\n",
        "# Training\n",
        "batch_size = 30\n",
        "epochs = 2\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "x_data = np.concatenate((x_train, x_test))\n",
        "y_data = np.concatenate((y_train, y_test))\n",
        "skf = StratifiedKFold(n_splits=5, random_state=42)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gecf8cVw_kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network Architecture\n",
        "def create_conv_mb_model(activation:str, branch_filters:[int], batch_normalize:bool=False,\n",
        "                         dropout:bool=False, dropout_rate:float=0.1, embedding_dropout:bool=False, \n",
        "                         embedding_dropout_rate:float=0.1):\n",
        "  # Multi-branch CNN\n",
        "  var_input = Input(shape=(400,))\n",
        "  emb_layer = Embedding(max_features,\n",
        "                      embedding_dims,\n",
        "                      input_length=maxlen)(var_input)\n",
        "  if embedding_dropout:\n",
        "    emb_layer = SpatialDropout1D(rate=embedding_dropout_rate)(emb_layer)\n",
        "  conv_branches = []\n",
        "  for filter_length in branch_filters:\n",
        "    conv_layer_1 = Conv1D(filters, kernel_size=filter_length, padding='valid', \n",
        "                          activation=activation, strides=1)(emb_layer)\n",
        "    if batch_normalize:\n",
        "          conv_layer_1 = BatchNormalization()(conv_layer_1)\n",
        "    maxpooling = GlobalMaxPooling1D()(conv_layer_1)\n",
        "    conv_branches.append(maxpooling)\n",
        "\n",
        "  merge_layer = concatenate(conv_branches)\n",
        "  if dropout:\n",
        "      merge_layer = Dropout(rate=dropout_rate, seed=42)(merge_layer)\n",
        "  dense_layer = Dense(1, activation='sigmoid')(merge_layer)\n",
        "  model = Model(inputs=var_input, outputs=dense_layer)\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp9FdfkmzAdU",
        "colab_type": "code",
        "outputId": "3b4698fd-05e5-4b8a-82a2-3e9fa55bde16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "for train, test in skf.split(x_data, y_data):\n",
        "  target = create_conv_mb_model(activation='relu', branch_filters=kernel_sizes)\n",
        "  target.fit(x_data[train], y_data[train],\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_data[test], y_data[test]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 68s 2ms/sample - loss: 0.3006 - accuracy: 0.8676 - val_loss: 0.2285 - val_accuracy: 0.9068\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 62s 2ms/sample - loss: 0.1334 - accuracy: 0.9512 - val_loss: 0.2330 - val_accuracy: 0.9117\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 60s 1ms/sample - loss: 0.3003 - accuracy: 0.8679 - val_loss: 0.2455 - val_accuracy: 0.9007\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 58s 1ms/sample - loss: 0.1327 - accuracy: 0.9516 - val_loss: 0.2551 - val_accuracy: 0.9086\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 59s 1ms/sample - loss: 0.2995 - accuracy: 0.8696 - val_loss: 0.2608 - val_accuracy: 0.8928\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 58s 1ms/sample - loss: 0.1358 - accuracy: 0.9496 - val_loss: 0.2351 - val_accuracy: 0.9081\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 61s 2ms/sample - loss: 0.3007 - accuracy: 0.8688 - val_loss: 0.2591 - val_accuracy: 0.8929\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 61s 2ms/sample - loss: 0.1329 - accuracy: 0.9509 - val_loss: 0.2414 - val_accuracy: 0.9093\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 59s 1ms/sample - loss: 0.3025 - accuracy: 0.8684 - val_loss: 0.2199 - val_accuracy: 0.9102\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 59s 1ms/sample - loss: 0.1356 - accuracy: 0.9493 - val_loss: 0.2180 - val_accuracy: 0.9156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH0etnVrTzrC",
        "colab_type": "code",
        "outputId": "f4f0bf21-9b9e-432b-d513-3f4e05c256d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "#Test w dropout\n",
        "for train, test in skf.split(x_data, y_data):\n",
        "  target = create_conv_mb_model(activation='relu', branch_filters=kernel_sizes,\n",
        "                                dropout=True)\n",
        "  target.fit(x_data[train], y_data[train],\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_data[test], y_data[test]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 62s 2ms/sample - loss: 0.3058 - accuracy: 0.8669 - val_loss: 0.2493 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 60s 2ms/sample - loss: 0.1466 - accuracy: 0.9447 - val_loss: 0.2517 - val_accuracy: 0.9068\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 61s 2ms/sample - loss: 0.3047 - accuracy: 0.8657 - val_loss: 0.2304 - val_accuracy: 0.9071\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 60s 1ms/sample - loss: 0.1424 - accuracy: 0.9480 - val_loss: 0.2423 - val_accuracy: 0.9070\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 61s 2ms/sample - loss: 0.3093 - accuracy: 0.8622 - val_loss: 0.2261 - val_accuracy: 0.9102\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 60s 2ms/sample - loss: 0.1490 - accuracy: 0.9451 - val_loss: 0.2815 - val_accuracy: 0.8951\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 61s 2ms/sample - loss: 0.3093 - accuracy: 0.8619 - val_loss: 0.2337 - val_accuracy: 0.9046\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 60s 1ms/sample - loss: 0.1489 - accuracy: 0.9441 - val_loss: 0.2344 - val_accuracy: 0.9123\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 59s 1ms/sample - loss: 0.3119 - accuracy: 0.8623 - val_loss: 0.2337 - val_accuracy: 0.9031\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 57s 1ms/sample - loss: 0.1502 - accuracy: 0.9436 - val_loss: 0.2099 - val_accuracy: 0.9184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWy58fq6Wys_",
        "colab_type": "text"
      },
      "source": [
        "0.1 Dropout doesn't seem to have any impact on the accuracy results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U2-FL7tdO1Q",
        "colab_type": "code",
        "outputId": "5dfd52f7-f8a7-4c82-eb40-006828be0e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "#Test w SELU\n",
        "for train, test in skf.split(x_data, y_data):\n",
        "  target = create_conv_mb_model(activation='selu', branch_filters=kernel_sizes)\n",
        "  target.fit(x_data[train], y_data[train],\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_data[test], y_data[test]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 60s 1ms/sample - loss: 0.3003 - accuracy: 0.8696 - val_loss: 0.2238 - val_accuracy: 0.9081\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 58s 1ms/sample - loss: 0.1336 - accuracy: 0.9516 - val_loss: 0.2324 - val_accuracy: 0.9112\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 56s 1ms/sample - loss: 0.2994 - accuracy: 0.8670 - val_loss: 0.2323 - val_accuracy: 0.9050\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 55s 1ms/sample - loss: 0.1374 - accuracy: 0.9498 - val_loss: 0.2412 - val_accuracy: 0.9074\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 57s 1ms/sample - loss: 0.3037 - accuracy: 0.8658 - val_loss: 0.2390 - val_accuracy: 0.9063\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 57s 1ms/sample - loss: 0.1345 - accuracy: 0.9507 - val_loss: 0.2389 - val_accuracy: 0.9089\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 57s 1ms/sample - loss: 0.3027 - accuracy: 0.8663 - val_loss: 0.2316 - val_accuracy: 0.9062\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 56s 1ms/sample - loss: 0.1370 - accuracy: 0.9497 - val_loss: 0.2207 - val_accuracy: 0.9142\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 57s 1ms/sample - loss: 0.3024 - accuracy: 0.8680 - val_loss: 0.2153 - val_accuracy: 0.9131\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 56s 1ms/sample - loss: 0.1357 - accuracy: 0.9507 - val_loss: 0.2261 - val_accuracy: 0.9158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvRCrRlWgxzN",
        "colab_type": "text"
      },
      "source": [
        "As expected, SELU activation in such a shallow network does not have a notable impact on accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF3wUblJpGd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "8a114fa7-f535-433d-c841-515ec6aeac37"
      },
      "source": [
        "#Test w 0.2 dropout\n",
        "for train, test in skf.split(x_data, y_data):\n",
        "  target = create_conv_mb_model(activation='relu', branch_filters=kernel_sizes,\n",
        "                                dropout=True, dropout_rate=0.2)\n",
        "  target.fit(x_data[train], y_data[train],\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_data[test], y_data[test]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 59s 1ms/sample - loss: 0.3141 - accuracy: 0.8608 - val_loss: 0.3520 - val_accuracy: 0.8543\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 57s 1ms/sample - loss: 0.1610 - accuracy: 0.9374 - val_loss: 0.2259 - val_accuracy: 0.9154\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 58s 1ms/sample - loss: 0.3124 - accuracy: 0.8613 - val_loss: 0.2394 - val_accuracy: 0.9060\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 57s 1ms/sample - loss: 0.1584 - accuracy: 0.9416 - val_loss: 0.2439 - val_accuracy: 0.9054\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 57s 1ms/sample - loss: 0.3120 - accuracy: 0.8613 - val_loss: 0.2308 - val_accuracy: 0.9080\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 56s 1ms/sample - loss: 0.1613 - accuracy: 0.9381 - val_loss: 0.2458 - val_accuracy: 0.9056\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 57s 1ms/sample - loss: 0.3137 - accuracy: 0.8603 - val_loss: 0.2440 - val_accuracy: 0.8979\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 56s 1ms/sample - loss: 0.1624 - accuracy: 0.9390 - val_loss: 0.2754 - val_accuracy: 0.8915\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "40000/40000 [==============================] - 56s 1ms/sample - loss: 0.3209 - accuracy: 0.8593 - val_loss: 0.2358 - val_accuracy: 0.9057\n",
            "Epoch 2/2\n",
            "40000/40000 [==============================] - 55s 1ms/sample - loss: 0.1647 - accuracy: 0.9357 - val_loss: 0.2421 - val_accuracy: 0.9036\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}